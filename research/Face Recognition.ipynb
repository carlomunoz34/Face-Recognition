{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e905c1-e2e2-4cc4-930d-1454fd1a668f",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ca014-925e-4c0b-b4b9-3d1e65c88989",
   "metadata": {},
   "source": [
    "In this notebook we are going to create and train a model for the problem of face recognition. The first step is to create and visualize the dataset, that is going to be the CelebA dataset. Next, we are going to pretrain a model to classify those faces, and finally, that pretrained model is what we are going to use as a baseline to create a siamese neural network to solve this face recognition problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f5302-22da-46be-8eb2-094e696cef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "from sklearn.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38f7b4-8d7e-48b1-a915-a61e3c213bc7",
   "metadata": {},
   "source": [
    "## First, lets create our dataset and visualize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58e6ee-9397-4ec2-aae4-94d865566f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, train=True, trans=None):\n",
    "        data_path = \"/media/carlo/16CA983262CDA30A/Datasets/CelebA/\"\n",
    "        images_path = data_path + \"img_align_celeba/*\"\n",
    "        identities_table = pd.read_csv(data_path + \"identity_CelebA.csv\").values\n",
    "        \n",
    "        # create a dictonary to get the identities easier\n",
    "        self.identities = {}\n",
    "        for image_name, label in identities_table:\n",
    "            self.identities[image_name] = label\n",
    "            \n",
    "        # get a list of all the paths to the images\n",
    "        images = glob(images_path)\n",
    "\n",
    "        if train:\n",
    "            self.images = images[:180000]\n",
    "        else:\n",
    "            self.images = images[180000:]\n",
    "            \n",
    "        if trans is not None:\n",
    "            self.transforms = trans\n",
    "        else:\n",
    "            self.transforms = transforms.ToTensor()\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        image_name = image_path.split(os.sep)[-1]\n",
    "        \n",
    "        # the labels are base 1, that why the -1\n",
    "        return image, torch.tensor(self.identities[image_name] - 1, dtype=torch.int64)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90b62c-1551-4d6c-a83e-e70f5a8079fc",
   "metadata": {},
   "source": [
    "Now, lets define our train and test transformers. For train, we are going to use data augmentation to avoid overtraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb613d2a-0f55-4696-a447-f9d1ef98b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 300, 300\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomResizedCrop((IMG_HEIGHT, IMG_WIDTH), (0.6, 1.0)),\n",
    "        transforms.RandomGrayscale(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CelebADataset(True, train_transforms)\n",
    "test_dataset = CelebADataset(False, test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30d158-c746-4f4b-ac48-a76dcc550bbb",
   "metadata": {},
   "source": [
    "Now, lets plot some images to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf1fd8-799a-4517-ad56-1b4539a2c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 4\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = train_dataset[i][0].numpy()\n",
    "    img = np.moveaxis(img, 0, 2)\n",
    "    img = np.clip(img, 0, 1)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0f12c-1263-46c2-af6e-e937cdd55c52",
   "metadata": {},
   "source": [
    "The color issues are due to the normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c56a6",
   "metadata": {},
   "source": [
    "Lets create a virtual dataloader to handle virtual epochs due to the large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ccb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirtualDataLoader:\n",
    "\n",
    "    def __init__(self, data_loader, steps_per_epoch: int = 1000):\n",
    "        self.data_loader = data_loader\n",
    "        self.iterator = iter(self.data_loader)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.current_step = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_step < self.steps_per_epoch:\n",
    "            self.current_step += 1\n",
    "            try:\n",
    "                return next(self.iterator)\n",
    "            except StopIteration:\n",
    "                self.iterator = iter(self.data_loader)\n",
    "                return next(self.iterator)\n",
    "        else:\n",
    "            self.current_step = 0\n",
    "            raise StopIteration\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776abb6",
   "metadata": {},
   "source": [
    "And now, create the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e475962",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset) + len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e42507",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "TRAIN_STEPS_PER_EPOCH = 25\n",
    "TEST_STEPS_PER_EPOCH = 25\n",
    "\n",
    "raw_train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "raw_test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    BATCH_SIZE,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "train_loader = VirtualDataLoader(raw_train_loader, TRAIN_STEPS_PER_EPOCH)\n",
    "test_loader = VirtualDataLoader(raw_test_loader, TEST_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16befc-1568-4b43-b022-4882f675abb7",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90085402-5682-4b85-b29f-70a62efc0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of labels \n",
    "labels = max(train_dataset.identities.values())\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d319fdf-7fb8-4255-a359-fc3e9853b8c6",
   "metadata": {},
   "source": [
    "Now, lets create the model to pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5491a-7f62-488e-98e3-9c88eda8b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, labels):\n",
    "        super().__init__()\n",
    "        self.base_model = models.efficientnet_b3(pretrained=True)\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(in_features=1536, out_features=labels, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db28a0-4ce4-4d96-950e-a02ed8bc6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = EfficientNet(labels).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bfa759",
   "metadata": {},
   "source": [
    "Lets define our train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08073dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, train_set, test_set, epochs_, step, learning_rate, model_name: str, path_to_save: str,\n",
    "          start_epoch_=0, adam: bool = True, patience: int = 5):\n",
    "    \"\"\"\n",
    "    Train a siamese network with Adam or RMSProp optimizer and contrastive loss.\n",
    "    :param model: torch.nn.Module\n",
    "        The Pytorch model to train\n",
    "    :param train_set: DataLoader\n",
    "        The data to train the model\n",
    "    :param test_set: DataLoader\n",
    "        The data to test the efficiency of the model\n",
    "    :param epochs_: int\n",
    "        The number of epochs to train. If -1, it will train until the early stopping stops the training\n",
    "    :param step: function\n",
    "        A function that receives a data sample from the dataset and returns the loss\n",
    "    :param learning_rate: float\n",
    "        Starting learning rate used during the train phase\n",
    "    :param model_name: str\n",
    "        Specify the model name, just to save the files correctly\n",
    "    :param path_to_save: str\n",
    "        The path to save the model\n",
    "    :param start_epoch_: int\n",
    "        To continue the training. Indicates in what epoch the current train will start.\n",
    "    :param adam: bool\n",
    "        If true, uses Adam as optimizer, if false uses RMSProp\n",
    "    :param patience: int\n",
    "        The number of epochs used in the early stopping\n",
    "    :return: (list, list)\n",
    "        The train and test losses\n",
    "    \"\"\"\n",
    "    losses_ = []\n",
    "    test_losses_ = []\n",
    "    best_score = float(\"inf\")\n",
    "    best_model = None\n",
    "    not_improved = 0\n",
    "    until_converge = False\n",
    "\n",
    "    if adam:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    if start_epoch_ != 0:\n",
    "        lr_scheduler.load_state_dict(torch.load(f\"{path_to_save}/lr_scheduler_{start_epoch_ - 1}.pt\"))\n",
    "\n",
    "    if epochs_ == -1:\n",
    "        epochs_ = start_epoch_ + 1\n",
    "        until_converge = True\n",
    "        \n",
    "    # to scale and train in fp16\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch = start_epoch_\n",
    "    while epoch < epochs_:\n",
    "        sys.stdout.flush()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for sample in tqdm(train_set, total=len(train_set), desc='Train'):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                current_loss = step(model, *sample)\n",
    "            \n",
    "            scaler.scale(current_loss).backward()\n",
    "\n",
    "            epoch_loss += current_loss.detach().cpu().item()\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        # Test step\n",
    "        sys.stdout.flush()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sample in tqdm(test_set, total=len(test_set), desc=\"Test\"):\n",
    "                test_loss += step(model, *sample).detach().cpu().item()\n",
    "\n",
    "        epoch_loss /= len(train_set)\n",
    "        test_loss /= len(test_set)\n",
    "        losses_.append(epoch_loss)\n",
    "        test_losses_.append(test_loss)\n",
    "\n",
    "        torch.save(model.state_dict(), f'{path_to_save}/{model_name}_{epoch + 1}.pt')\n",
    "        torch.save(lr_scheduler.state_dict(), f'{path_to_save}/lr_scheduler_{epoch + 1}.pt')\n",
    "\n",
    "        # Get the best model\n",
    "        if test_loss < best_score:\n",
    "            best_score = test_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            not_improved = 0\n",
    "\n",
    "        else:\n",
    "            not_improved += 1\n",
    "\n",
    "        if until_converge:\n",
    "            epochs_ += 1\n",
    "            message = f'Epoch: {epoch + 1}, Loss: {epoch_loss:.4f}, ' + \\\n",
    "                      f'Test loss: {test_loss:.4f}, Epochs w/o improvement: {not_improved}\\n'\n",
    "            full_message = f'Epoch: {epoch + 1}, Loss: {epoch_loss}, ' + \\\n",
    "                           f'Test loss: {test_loss}, Epochs w/o improvement: {not_improved}\\n'\n",
    "        else:\n",
    "            message = f'Epoch: {epoch + 1}/{epochs_}, Loss: {epoch_loss:.4f}, ' + \\\n",
    "                      f'Test loss: {test_loss:.4f}, Epochs w/o improvement: {not_improved}\\n'\n",
    "            full_message = f'Epoch: {epoch + 1}/{epochs_}, Loss: {epoch_loss}, ' + \\\n",
    "                           f'Test loss: {test_loss}, Epochs w/o improvement: {not_improved}\\n'\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(message)\n",
    "\n",
    "        with open(f'{path_to_save}/train_{model_name}.log', 'a') as f:\n",
    "            f.write(full_message)\n",
    "            f.close()\n",
    "\n",
    "        # Early stopping\n",
    "        if not_improved == patience:\n",
    "            break\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    torch.save(best_model, f'{path_to_save}/best-{model_name}.pt')\n",
    "    return losses_, test_losses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ebfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(labels, predictions) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba29c6d",
   "metadata": {},
   "source": [
    "And implement a step of the face classification training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_train_step(model, images, labels):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    predictions = model(images)\n",
    "\n",
    "    return F.cross_entropy(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e069db",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, test_losses = train(\n",
    "    model=model,\n",
    "    train_set=train_loader,\n",
    "    test_set=test_loader,\n",
    "    epochs_=20,\n",
    "    step=classification_train_step,\n",
    "    learning_rate=0.001,\n",
    "    model_name=\"b3_classification\",\n",
    "    path_to_save=\"./models\",\n",
    "    patience=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6376fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.plot(losses[0], losses[1], c='red', label='train loss')\n",
    "# plt.plot(test_losses[:, 0], test_losses[:, 1], c='blue', label='test loss')\n",
    "# plt.xlabel('Steps')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef938d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (face)",
   "language": "python",
   "name": "face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
